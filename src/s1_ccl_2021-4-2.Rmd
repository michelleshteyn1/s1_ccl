---
title: 'Study 1: CCL Members'
author: "Michelle Shteyn Handy"
date: "4/02/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Attach packages
library(tidyverse)
library(here)
library(lubridate)
library(janitor)
library(kableExtra)
library(writexl)
library(ggpubr)
library(rstatix)
library(psych)

```

Notes 4/12/21:  

- clean up the code  
- I don't need to do t-tests on all 3 zero-order: effect of exp condition on self-stereotype NOT necessary because the experiment happened AFTER people ranked self and stereotype  
- Should I identify outliers and remove them from the dataset before all analyses? So far, I only removed outliers from the main ANOVA and now it shows the expected pattern more.

# Conduct power analysis

The present study employs a repeated measures design with a between-subjects factor (experimental condition: similarity vs. dissimilarity). Stereotyping and projection constructs were computed within-participant across items. Conduct power analysis for repeated measures ANOVA with a within-between interaction, assuming a small effect size (f = 0.1).

*This was already done in GPower, figure out how to do in R so it's all in one place.
```{r}

```


# Read in data and delete previews
Remove participants who:

- Took survey before 3-12-2021 (when Brett sent out the 1st recruitment message)
- Had less than 90% progress
- Completed study in less than 5 minutes or more than 120 minutes (I want people who did not rush and also did it in 1 sitting)
- Were previews

```{r, warning=FALSE, message=FALSE}

# Read in dataset from the "data" subfolder

ccl <- read_csv(here("data","s1_ccl_2021-4-2.csv"))

# Do some wrangling

ccl <- ccl[-c(1:2),] %>% # Delete the first two rows of Qualtrics meta-data
  separate(StartDate, c("date","time"), sep = " ") %>%  # Use the `separate` function to separate into two rows: date and time
  mutate(date = ymd(date)) %>%  # Convert `date` column from character to a stored date class
  filter(date >= as.Date("2021-03-12")) %>%  # Delete any rows before 3-12-2021 
  filter(Status != "Survey Preview") %>% # Delete any survey previews (there was 1)
  filter(ResponseId != "R_3e2HW1XRAHaDuSv") # Remove David's response from when he previewed
  
# We recruited 200 people from a list of 5000 CCL members. After the wrangling above, it shows that 286 CCL members took the survey (this includes those who started it but did not complete it, their data was recorded)

# Do some more wrangling to filter out participants who:
    # had progress less than 90%
    # took the survey in between 5 and 120 minutes 

ccl <- ccl %>% 
  clean_names() %>% # Change variable names to `lower_snake_case`
  mutate(progress = as.numeric(progress), # Convert progress and duration variables into numeric class
         duration_in_seconds = as.numeric(duration_in_seconds),
         duration_in_minutes = duration_in_seconds/60) %>% 
  filter(progress > 90) %>% # Filter for progress over 90% and between 5 and 120 minutes
  filter(duration_in_minutes >= 5) %>% 
  filter(duration_in_minutes <= 120)

# Now we are left with 161 participants being included in analyses.

# Save clean data in `data` folder

#write_csv(ccl, here("data","ccl_clean.csv"))

# I checked it out manually, all of the data looks good now.
```

# Data cleaning and calculating constructs

### Reverse coding

Reverse code ranking items (`self_1`, `stereotype_1`, `robert_1` through `self_8`, `stereotype_8`, `robert_8`) using `mutate::case_when()` such that higher scores indicate greater importance of the reasons for supporting the Energy Innovation & Carbon Dividend Act:

*Note*: Reverse coding doesn't actually matter for calculation of the stereotyping and projection constructs, but will be useful to look at which reasons participants prioritized most. 

```{r, warning=FALSE, message=FALSE}

# Reverse code self ranking items

ccl <- ccl %>% 
  mutate(s1 = case_when(
                   self_1 == 1 ~ 8, 
                   self_1 == 2 ~ 7, 
                   self_1 == 3 ~ 6, 
                   self_1 == 4 ~ 5, 
                   self_1 == 5 ~ 4,
                   self_1 == 6 ~ 3, 
                   self_1 == 7 ~ 2,
                   self_1 == 8 ~ 1),
         s2 = case_when(
                   self_2 == 1 ~ 8, 
                   self_2 == 2 ~ 7, 
                   self_2 == 3 ~ 6, 
                   self_2 == 4 ~ 5, 
                   self_2 == 5 ~ 4,
                   self_2 == 6 ~ 3, 
                   self_2 == 7 ~ 2,
                   self_2 == 8 ~ 1),
         s3 = case_when(
                   self_3 == 1 ~ 8, 
                   self_3 == 2 ~ 7, 
                   self_3 == 3 ~ 6, 
                   self_3 == 4 ~ 5, 
                   self_3 == 5 ~ 4,
                   self_3 == 6 ~ 3, 
                   self_3 == 7 ~ 2,
                   self_3 == 8 ~ 1),
         s4 = case_when(
                   self_4 == 1 ~ 8, 
                   self_4 == 2 ~ 7, 
                   self_4 == 3 ~ 6, 
                   self_4 == 4 ~ 5, 
                   self_4 == 5 ~ 4,
                   self_4 == 6 ~ 3, 
                   self_4 == 7 ~ 2,
                   self_4 == 8 ~ 1),
         s5 = case_when(
                   self_5 == 1 ~ 8, 
                   self_5 == 2 ~ 7, 
                   self_5 == 3 ~ 6, 
                   self_5 == 4 ~ 5, 
                   self_5 == 5 ~ 4,
                   self_5 == 6 ~ 3, 
                   self_5 == 7 ~ 2,
                   self_5 == 8 ~ 1),
         s6 = case_when(
                  self_6 == 1 ~ 8, 
                   self_6 == 2 ~ 7, 
                   self_6 == 3 ~ 6, 
                   self_6 == 4 ~ 5, 
                   self_6 == 5 ~ 4,
                   self_6 == 6 ~ 3, 
                   self_6 == 7 ~ 2,
                   self_6 == 8 ~ 1),
         s7 = case_when(
                   self_7 == 1 ~ 8, 
                   self_7 == 2 ~ 7, 
                   self_7 == 3 ~ 6, 
                   self_7 == 4 ~ 5, 
                   self_7 == 5 ~ 4,
                   self_7 == 6 ~ 3, 
                   self_7 == 7 ~ 2,
                   self_7 == 8 ~ 1),
         s8 = case_when(
                   self_8 == 1 ~ 8, 
                   self_8 == 2 ~ 7, 
                   self_8 == 3 ~ 6, 
                   self_8 == 4 ~ 5, 
                   self_8 == 5 ~ 4,
                   self_8 == 6 ~ 3, 
                   self_8 == 7 ~ 2,
                   self_8 == 8 ~ 1))

# Reverse code stereotype ranking items

ccl <- ccl %>% 
  mutate(g1 = case_when(
                   stereotype_1 == 1 ~ 8, 
                   stereotype_1 == 2 ~ 7, 
                   stereotype_1 == 3 ~ 6, 
                   stereotype_1 == 4 ~ 5, 
                   stereotype_1 == 5 ~ 4,
                   stereotype_1 == 6 ~ 3, 
                   stereotype_1 == 7 ~ 2,
                   stereotype_1 == 8 ~ 1),
         g2 = case_when(
                   stereotype_2 == 1 ~ 8, 
                   stereotype_2 == 2 ~ 7, 
                   stereotype_2 == 3 ~ 6, 
                   stereotype_2 == 4 ~ 5, 
                   stereotype_2 == 5 ~ 4,
                   stereotype_2 == 6 ~ 3, 
                   stereotype_2 == 7 ~ 2,
                   stereotype_2 == 8 ~ 1),
         g3 = case_when(
                   stereotype_3 == 1 ~ 8, 
                   stereotype_3 == 2 ~ 7, 
                   stereotype_3 == 3 ~ 6, 
                   stereotype_3 == 4 ~ 5, 
                   stereotype_3 == 5 ~ 4,
                   stereotype_3 == 6 ~ 3, 
                   stereotype_3 == 7 ~ 2,
                   stereotype_3 == 8 ~ 1),
         g4 = case_when(
                   stereotype_4 == 1 ~ 8, 
                   stereotype_4 == 2 ~ 7, 
                   stereotype_4 == 3 ~ 6, 
                   stereotype_4 == 4 ~ 5, 
                   stereotype_4 == 5 ~ 4,
                   stereotype_4 == 6 ~ 3, 
                   stereotype_4 == 7 ~ 2,
                   stereotype_4 == 8 ~ 1),
         g5 = case_when(
                   stereotype_5 == 1 ~ 8, 
                   stereotype_5 == 2 ~ 7, 
                   stereotype_5 == 3 ~ 6, 
                   stereotype_5 == 4 ~ 5, 
                   stereotype_5 == 5 ~ 4,
                   stereotype_5 == 6 ~ 3, 
                   stereotype_5 == 7 ~ 2,
                   stereotype_5 == 8 ~ 1),
         g6 = case_when(
                  stereotype_6 == 1 ~ 8, 
                   stereotype_6 == 2 ~ 7, 
                   stereotype_6 == 3 ~ 6, 
                   stereotype_6 == 4 ~ 5, 
                   stereotype_6 == 5 ~ 4,
                   stereotype_6 == 6 ~ 3, 
                   stereotype_6 == 7 ~ 2,
                   stereotype_6 == 8 ~ 1),
         g7 = case_when(
                   stereotype_7 == 1 ~ 8, 
                   stereotype_7 == 2 ~ 7, 
                   stereotype_7 == 3 ~ 6, 
                   stereotype_7 == 4 ~ 5, 
                   stereotype_7 == 5 ~ 4,
                   stereotype_7 == 6 ~ 3, 
                   stereotype_7 == 7 ~ 2,
                   stereotype_7 == 8 ~ 1),
         g8 = case_when(
                   stereotype_8 == 1 ~ 8, 
                   stereotype_8 == 2 ~ 7, 
                   stereotype_8 == 3 ~ 6, 
                   stereotype_8 == 4 ~ 5, 
                   stereotype_8 == 5 ~ 4,
                   stereotype_8 == 6 ~ 3, 
                   stereotype_8 == 7 ~ 2,
                   stereotype_8 == 8 ~ 1))

# Reverse code robert ranking items

ccl <- ccl %>% 
  mutate(r1 = case_when(
                   robert_1 == 1 ~ 8, 
                   robert_1 == 2 ~ 7, 
                   robert_1 == 3 ~ 6, 
                   robert_1 == 4 ~ 5, 
                   robert_1 == 5 ~ 4,
                   robert_1 == 6 ~ 3, 
                   robert_1 == 7 ~ 2,
                   robert_1 == 8 ~ 1),
         r2 = case_when(
                   robert_2 == 1 ~ 8, 
                   robert_2 == 2 ~ 7, 
                   robert_2 == 3 ~ 6, 
                   robert_2 == 4 ~ 5, 
                   robert_2 == 5 ~ 4,
                   robert_2 == 6 ~ 3, 
                   robert_2 == 7 ~ 2,
                   robert_2 == 8 ~ 1),
         r3 = case_when(
                   robert_3 == 1 ~ 8, 
                   robert_3 == 2 ~ 7, 
                   robert_3 == 3 ~ 6, 
                   robert_3 == 4 ~ 5, 
                   robert_3 == 5 ~ 4,
                   robert_3 == 6 ~ 3, 
                   robert_3 == 7 ~ 2,
                   robert_3 == 8 ~ 1),
         r4 = case_when(
                   robert_4 == 1 ~ 8, 
                   robert_4 == 2 ~ 7, 
                   robert_4 == 3 ~ 6, 
                   robert_4 == 4 ~ 5, 
                   robert_4 == 5 ~ 4,
                   robert_4 == 6 ~ 3, 
                   robert_4 == 7 ~ 2,
                   robert_4 == 8 ~ 1),
         r5 = case_when(
                   robert_5 == 1 ~ 8, 
                   robert_5 == 2 ~ 7, 
                   robert_5 == 3 ~ 6, 
                   robert_5 == 4 ~ 5, 
                   robert_5 == 5 ~ 4,
                   robert_5 == 6 ~ 3, 
                   robert_5 == 7 ~ 2,
                   robert_5 == 8 ~ 1),
         r6 = case_when(
                  robert_6 == 1 ~ 8, 
                   robert_6 == 2 ~ 7, 
                   robert_6 == 3 ~ 6, 
                   robert_6 == 4 ~ 5, 
                   robert_6 == 5 ~ 4,
                   robert_6 == 6 ~ 3, 
                   robert_6 == 7 ~ 2,
                   robert_6 == 8 ~ 1),
         r7 = case_when(
                   robert_7 == 1 ~ 8, 
                   robert_7 == 2 ~ 7, 
                   robert_7 == 3 ~ 6, 
                   robert_7 == 4 ~ 5, 
                   robert_7 == 5 ~ 4,
                   robert_7 == 6 ~ 3, 
                   robert_7 == 7 ~ 2,
                   robert_7 == 8 ~ 1),
         r8 = case_when(
                   robert_8 == 1 ~ 8, 
                   robert_8 == 2 ~ 7, 
                   robert_8 == 3 ~ 6, 
                   robert_8 == 4 ~ 5, 
                   robert_8 == 5 ~ 4,
                   robert_8 == 6 ~ 3, 
                   robert_8 == 7 ~ 2,
                   robert_8 == 8 ~ 1))

```

### Create binary variables: gender and ideology

Create 2 binary variables:

- `gender_bin` (Male/Female)  
- `lib_con` (Liberal = Very liberal, liberal; Conservative = Moderate, Conservative, & Very conservative)
```{r, message=FALSE, warning=FALSE}

ccl <- ccl %>% 
  mutate(gender_bin = case_when(
    gender=="Female"~"Female",
    gender=="Male"~"Male"),
  gender_bin = as.factor(gender_bin), # Make sure `gender_bin` is a factor variable
  lib_con = case_when(
    ideology=="Very liberal"~"Liberal",
    ideology=="Liberal"~"Liberal",
    ideology=="Moderate"~"Conservative",
    ideology=="Conservative"~"Conservative",
    ideology=="Very conservative"~"Conservative"
  ),
  lib_con = as.factor(lib_con)) # Make sure `lib_con` is a factor variable
```

### Create binary variable: normative vs. non-normative

Create new variable `normative`. Code participants as concordant or non-concordant with the predominant social norm (in this population, predominant social norm =  like camping, adventurous vacations, don't like scary movies (summarized a few headings down)).  

- Non-concordant = 0 or 1 attributes that are most common, Concordant = have all 3 of the common attributes.

```{r, message=FALSE, warning=FALSE}

ccl <- ccl %>% 
  mutate(normative = case_when(
  outdoor_art=="Camping" & vacation == "Adventurous" & scary_movie == "No" ~ "Normative", 
   outdoor_art=="Staying in and watching TV shows" & vacation == "Relaxing" & scary_movie == "Yes" ~ "Non-normative", 
  outdoor_art=="Camping" & vacation == "Relaxing" & scary_movie == "Yes" ~ "Non-normative",
  outdoor_art=="Staying in and watching TV shows" & vacation == "Adventurous" & scary_movie == "Yes" ~ "Non-normative",
   outdoor_art=="Staying in and watching TV shows" & vacation == "Relaxing" & scary_movie == "No" ~ "Non-normative",
))

ccl %>% 
  group_by(normative) %>% 
  summarise(counts = n(),
            percent = n()/161*100) %>% 
kable(col.names = c("Normative (have all 3 common traits) vs. Non-normative (have 0 or 1 common traits)",
                      "Counts",
                    "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

```



### Create secondary DVs: average of Robert 6,7,8 (projection) and Robert 1,2,3 (stereotyping)

Summary statistics a few headings down show that CCL activists' top 3 reasons for self were 7, 8, and 6: the typical environmentalist ones.  
- 7: "It will keep the Earth from warming more than 1.5 degrees Celsius above pre-industrial levels, at which point irreversible damages to our planet - including polar ice sheet collapse, disease, and famines - would occur"  
- 8: "It will be a crucial step in mitigating the climate crisis that we have caused and therefore have the responsibility to solve."  
- 6: "It will ensure that we leave behind a safe and habitable planet for future generations to enjoy."  

The top 3 reasons participants ranked for typical businessman (and Robert) were 2, 3, and 1: the typical business-y ones. 
- 2: "It will create a demand for local jobs and boost local economies as American families spend their monthly carbon dividends in their communities."  
- 3: "It will prevent communities and local businesses from losing billions of dollars on damages caused by climate-change related disasters."  
- 1: "It will drive innovation and put our country on the forefront of a transition to a clean energy economy."

Averaging the top 3 reasons for self and the top 3 reasons for the stereotypical businessman can serve as secondary DVs of projection and stereotyping.  
- First, I will calculate the Cronbach's alpha for 6,7,8 and 1,2,3 to show that the two groups of reasons hang together (for 6,7,8 across self, group, and Robert rankings, alpha = .48; for 1,2,3 across self, group, and Robert rankings, alpha = .46). Then, I'll average the two groups and treat them both like scales.  
- To clarify, I will average participants' rankings of 6, 7, 8 *for Robert* (`r6`, `r7`, `r8`) as projection, and participants' rankings of 1, 2, 3 *for Robert* (`r1`, `r2`, `r3`) as stereotyping.

```{r, message=FALSE, warning=FALSE}
# Calculate alpha of s6, s7, s8 to see if the items hang together for self
self_678 <- ccl %>% 
  select(s6,s7,s8)
#alpha(self_678) #alpha = .10, 95% CI [-.14, .34]

# Calculate alpha of g1, g2, g3 to see if the items hang together for typical group member
group_123 <- ccl %>% 
  select(g1,g2,g3)
#alpha(group_123) #alpha = .17, 95% CI [-.05, .40]

# Look at alphas for Robert since those are the items I will create the scales from
robert_678 <- ccl %>% 
  select(r6,r7,r8)
#alpha(robert_678) #alpha = .28, 95% CI [.09, .47]

robert_123<-ccl %>% 
  select(r1,r2,r3)
#alpha(robert_123) #alpha = .16, 95% CI [-.07, .38]


#Overall, do 1,2,3 hang together and do 6,7,8 hang together?

sgr_678 <- ccl %>% 
  select(s6,s7,s8,g6,g7,g8,r6,r7,r8)
#alpha(sgr_678) #alpha = .49, 95% CI [.36, .61]

sgr_123 <- ccl %>% 
  select(s1,s2,s3,g1,g2,g3,r1,r2,r3)
#alpha(sgr_123) #alpha = .47, 95% CI [.35, .59]

```


```{r, message=FALSE, warning=FALSE}
# Create the DVs using `mutate` function

ccl <- ccl %>% 
  mutate(projection_678 = (r6+r7+r8)/3, # create a new variable `projection_678' which averages whenever Ss ranked 6,7,8 for robert
         stereotyping_123 = (r1+r2+r3)/3) # create a new variable `stereotyping_123' which averages whenever Ss ranked 1,2,3 for robert

```



# Descriptives

### Race / Ethnicity 

1 'multi-racial' person identified as "white and hispanic"; 1 'other' identified as "European." 
```{r, warning=FALSE,message=FALSE}
ccl %>% 
  group_by(race) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
  kable(col.names = c("Race/Ethnicity",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left") # How do I get percent to stop at 2 decimal places?
```

```{r, warning=FALSE,message=FALSE}
# Multi-racial (open-ended)
ccl %>% 
  group_by(race_6_text) %>% 
  summarise(count = n()) %>% 
  kable(col.names = c("Race/Ethnicity: Multi-racial - Text",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

# Other (open-ended)
ccl %>% 
  group_by(race_7_text) %>% 
  summarise(count = n()) %>% 
  kable(col.names = c("Race/Ethnicity: Other - Text",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```

### Age, household income, gender

### Age
Participants ranged from 18 to 84 years old (median = 66, *SD* = 16.84 years). Three participants wrote in their own responses: "Older than you," "70 (Retired)," "over 60."
```{r, warning=FALSE,message=FALSE}
## AGE

# First I created a subset of just the age variable so I could filter out the text responses and convert this variable to numeric. After examining the variable, I saw the 3 text responses so I'm going to filter those out here:

age_subset <- ccl %>% 
  select(age) %>% 
  filter(age != "70 (Retired)") %>% 
  filter(age != "Older than you") %>% 
  filter(age != "over 60") 

#Convert the age variable to numeric
age_subset <- age_subset %>% 
  mutate(age = as.numeric(age)) %>% 
  drop_na()

# Find descriptives
#mean(age_subset$age) # 60.45
#sd(age_subset$age) # 16.84
#min(age_subset$age) # 18
#max(age_subset$age) # 84
#median(age_subset$age) # 66
```


### Household income

Median household income category was 5: $50,001 to $75,000.

*Figure out how to label tick marks on x-axis.

```{r, warning=FALSE, message=FALSE}
## HOUSEHOLD INCOME

#First, change family income into a factor variable

ccl <- ccl %>% 
  mutate(fam_inc_num = case_when(
    fam_inc == "Under $15,000" ~ 1,
    fam_inc == "$15,001 - $25,000" ~ 2,
    fam_inc == "$25,001 - $35,000" ~ 3,
    fam_inc == "$35,001 - $50,000" ~ 4, 
    fam_inc == "$50,001 - $75,000" ~ 5,
    fam_inc == "$75,001 - $100,000" ~ 6, 
    fam_inc == "$100,001 - $150,000" ~ 7,
    fam_inc == "$Over 150,000" ~ 8))

#IDK why the labeling doesn't work

ggplot(data = ccl, aes(x = fam_inc_num)) +
  geom_histogram(stat = "count") +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_x_discrete(breaks=c("1","2","3","4","5","6","7"),  
                      labels=c("Under $15,000", "$15,001 - $25,000", "$25,001 - $35,000",
                  "$35,001 - $50,000","$50,001 - $75,000","$75,001 - $100,000",
                  "$100,001 - $150,000"))


#median(ccl$fam_inc_num, na.rm = TRUE) # 5
#min(ccl$fam_inc_num, na.rm = TRUE) # 1
#max(ccl$fam_inc_num, na.rm = TRUE) # 7
```


### Gender

```{r, warning=FALSE, message=FALSE}
## GENDER

ccl %>% 
  group_by(gender) %>% 
  summarise(count = n(),
            percent = n()/(64+97+1)*100) %>% 
  kable(col.names = c("Gender",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```

### Political orientation

```{r, warning=FALSE,message=FALSE}
ccl %>% 
  group_by(ideology) %>% 
  summarise(count = n()) %>% 
  kable(col.names = c("Political Ideology",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")


ccl <- ccl %>% 
  mutate(pol_7_pt = case_when(
    dem_strong_weak == "Strong Democrat" ~ 1,
    dem_strong_weak == "Not Very Strong Democrat" ~ 2, 
    closer_dem_rep == "Closer to Democratic Party" ~ 3,
    closer_dem_rep == "Neither" ~ 4,
    closer_dem_rep == "Closer to Republican Party" ~ 5, 
    rep_strong_weak == "Not Very Strong Republican" ~ 6,
    rep_strong_weak == "Strong Republican" ~ 7
  ))

#mean(ccl$pol_7_pt) #2.16

ccl <- ccl %>% 
  mutate(pol_7_pt_char = case_when(
    dem_strong_weak == "Strong Democrat" ~ "Strong Democrat",
    dem_strong_weak == "Not Very Strong Democrat" ~ "Not Very Strong Democrat", 
    closer_dem_rep == "Closer to Democratic Party" ~ "Closer to Democratic Party",
    closer_dem_rep == "Neither" ~ "Neither",
    closer_dem_rep == "Closer to Republican Party" ~ "Closer to Republican Party", 
    rep_strong_weak == "Not Very Strong Republican" ~ "Not Very Strong Republican",
    rep_strong_weak == "Strong Republican" ~ "Strong Republican"
  ))

ccl %>% 
  group_by(pol_7_pt) %>% 
  summarise(count = n()) %>% 
  kable(col.names = c("Political Party Identification",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```


# Participants' answers on the similarity questions

Their responses reveal expected levels of variance in the population: 27.78% enjoy relaxing vacations (vs. 71.60% adventurous), 17.28% enjoy scary movies, and 70.99% enjoy camping (vs. 27.16% staying in and watching TV shows).

```{r, message=FALSE, warning=FALSE}
ccl %>% 
  group_by(vacation) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
   kable(col.names = c("Vacation Preference",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

ccl %>% 
  group_by(scary_movie) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
   kable(col.names = c("Enjoy Scary Movies?",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

ccl %>% 
  group_by(outdoor_art) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
   kable(col.names = c("Prefer Camping or Staying In and Watching TV Shows?",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```
# Counts in each experimental condition

79 in the dissimilarity condition, 82 in the similarity condition.
```{r, message=FALSE, warning=FALSE}
ccl %>% 
  group_by(group) %>% 
  summarize(count = n()) %>% 
  kable(col.names = c("Experimental Condition",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```
# Show that similarity condition worked

Show that people's responses matched to Robert's on Qualtrics if in the similarity condition, and were opposite to Robert's responses if in the different condition. See PDF of participant `R_Cmo4fj6vBoORfgt`'s response, saved in my "Methods" folder, where it shows that the similarity manipulation functioned properly. 
```{r}

```


# Calculate stereotyping and projection constructs

For each participant, a multiple regression predicting target responses with self-responses and typical business owner responses was computed (across the 8 reasons to support the Energy Innovation & Carbon Dividend Act). The standardized beta weights were then used as measures of projection (the self-response beta) and stereotyping (the typical businessman response beta).  

- Need to use `pivot_longer()` to manipulate the data into the correct format for analysis: `reason_number` (1-8), `self_rankings`, `stereotype_rankings`, and `robert_rankings` become new variables. Use [this resource](https://tidyr.tidyverse.org/reference/pivot_longer.html) for `pivot_longer()`: anscombe example, multiple observations per row.  
- Run MLR for each participant to predict Robert rankings from self- and group- rankings.Then add the standardized beta weights into new columns for projection and stereotyping. To automate these calculations (otherwise I would have to filter for one participant at a time), run the regressions on a loop. [Resource for running regressions on a loop.](https://stackoverflow.com/questions/27952653/how-to-loop-repeat-a-linear-regression-in-r)

```{r, message=FALSE, warning=FALSE, results='hide'}

# Create a new row called `id` which assigns each Ss an ID number based on the row they are in
ccl <- ccl %>% 
  mutate(id = row_number())

# Use `pivot_longer()` to make the data tidy and have variables for: reason_number, self_rankings, stereotype_rankings, robert_rankings
ccl_long <- ccl %>% 
  pivot_longer(
    cols = s1:r8,
    names_to = c(".value","reason_number"),
    names_pattern = "(.)(.)",
    values_drop_na = TRUE
  )

#Create subset with just the variables I'm interested in
stereotyping_projection_subset<-ccl_long %>% 
  select(id,reason_number,group,s,g,r, gender_bin, lib_con, normative, projection_678, stereotyping_123) %>% 
  rename(self_rankings = s,
         stereotype_rankings = g,
         robert_rankings = r) %>% 
  add_column(projection = 0) %>% # Adding two new cols. to get ready for regressions on a loop
  add_column(stereotyping = 0)


#Calculate the multiple regressions for every participant 

# For loop will iterate through each row of the dataframe
# The scope of every action within the for loop is limited to that single iteration, so no need to manually filter data and calculate regression for each participant
for (i in 1:nrow(stereotyping_projection_subset)) {
  
  # This creates a dataframe of one row, the row that the for loop is currently on
  id<-stereotyping_projection_subset %>% 
    filter(id==stereotyping_projection_subset[[i, 1]])
  
  # This runs the MLR using the single row created above as the dataframe
  temp_lm <- lm(robert_rankings ~ self_rankings + stereotype_rankings, data = id)
  
  # This converts the linear model object created above into an easy to read and easy to access object. This essentially cleans up the output.
  tidy_temp_lm<-broom::tidy(temp_lm)
  
  # This creates a variable to store the beta coefficient for self ranking predicting robert ranking for this single row
  temp_self_rankings<-tidy_temp_lm[2, 2]
  
  # This creates a variable to store the beta coefficient for stereotype ranking predicting robert ranking for this single row
  temp_stereotype_rankings<-tidy_temp_lm[3,2]
  
  # The last two lines store the variables created above in columns in the original dataframe in the row that the for loop is currently on
  stereotyping_projection_subset[i, 12]<-temp_self_rankings
  stereotyping_projection_subset[i, 13]<-temp_stereotype_rankings
}

# Example of what is happening on each row in the for loop
# Example uses row 2

#id2<-stereotyping_projection_subset %>% 
#  filter(id==2)
#lm2 <- lm(robert_rankings ~ self_rankings + stereotype_rankings, data = id2)
#lm2
#Coefficients:
#        (Intercept)        self_rankings  stereotype_rankings  
#           -3.3750               0.7829               0.9671  
 

```


# Effects of similarity on projection and stereotyping

Conduct repeated-measures ANOVA to examine the effect of similarity condition (similar vs. different) and the two-level factor of projection and stereotyping on participants' stereotyping and projection scores. 

[Resource on two-way repeated measures ANOVA.](https://www.datanovia.com/en/lessons/repeated-measures-anova-in-r/#data-preparation-1)

## Data preparation

The projection and stereotyping scores were calculated from participants' rankings during the study. The question is to investigate if experimental condition can induce significant differences of projection and stereotyping scores over rankings during the study. In other terms, we wish to know if there is a significant interaction between `group` and `ranking` on the projection and stereotyping score.

Load and show on random row by treatment group:
```{r, warning=FALSE, message=FALSE}
#Create a subset of only the variables I need for this analysis: id, group, projection scores, and stereotyping scores
#Then rename exp_condition to group so it's more intuitive

anova_data <- stereotyping_projection_subset %>% 
  select(id, group, projection, stereotyping) %>% 
  rename(exp_condition = group)

# Wide format
set.seed(123)
anova_data %>% 
  sample_n_by(exp_condition, size = 1)

```

```{r}
# Gather the columns projection and stereotyping into long format.
# Convert id and group into factor variables
anova_data2 <- anova_data %>% 
  gather(key = "ranking", value = "score", projection, stereotyping) %>% 
  convert_as_factor(id, ranking) %>% 
  unique() %>% 
  mutate(exp_condition = as_factor(exp_condition))

# Inspect some random rows of the data by groups
set.seed(123)
anova_data2 %>% 
  sample_n_by(exp_condition, ranking, size = 1)
```


## Visualization

Create box plots of the score colored by experimental condition:

```{r, warning=FALSE, message=FALSE}
bxp <- ggboxplot(
  anova_data2, x = "ranking", y = "score",
  color = "exp_condition", palette = "jco"
) +
  labs(y = "Mean standardized beta") +
  theme(axis.title.x = element_blank())

bxp
```


## Check Assumptions

Verify that the data meets the required assumptions for two-way repeated measures ANOVA:  

- No significant outliers
- Normality
- Assumption of sphericity

### Outliers

There are 9 extreme outliers: id 4, 34, 118, 49, 87, 105, 49, 64, 105. **NOTE**: 49's answers for projection and stereotyping are both outliers. **Remove from dataset** for the primary repeated-measures ANOVA analysis.
```{r, warning=FALSE, message=FALSE}
anova_data2 %>% 
  group_by(exp_condition, ranking) %>% 
  identify_outliers(score)

# Remove 9 outliers from dataset

anova_data2 <- anova_data2 %>% 
  filter(id != 4, 
         id != 34,
         id != 118,
         id != 49,
         id != 87,
         id != 105,
         id != 64,
         id != 105)
```


### Normality assumption

Compute Shapiro-Wilk test for each combination of factor levels:

This shows that the scores for projection and stereotyping were NOT normally distributed at lines 2 and 4 (*p* < .05)
```{r, warning=FALSE, message=FALSE}
anova_data2 %>% 
  group_by(exp_condition, ranking) %>% 
  shapiro_test(score)
```


Create QQ plot for each cell of design:

```{r, warning=FALSE, message=FALSE}
ggqqplot(anova_data2, "score", ggtheme = theme_bw())+
  facet_grid(ranking~exp_condition, labeller = "label_both")
```

From the plot above, as all the points fall approximately along the reference line, we can assume normality.


## Compute the Two-Way ANOVA:

```{r, message=FALSE, warning=FALSE}
#res.aov <- anova_test(
#  data = anova_data2, dv = score, wid = id,
#  within = c(exp_condition, ranking)
#)

# I got an error, let me try to omit NAs from my data
anova_data2 <- anova_data2 %>% 
  drop_na()

#Still didn't work

#Two other tutorials said to do it the below ways and it worked. Although now it says ANOVA table (type II tests) rather than (type III tests like in the original tutorial)

#Solution from this tutorial: https://stats.idre.ucla.edu/r/seminars/repeated-measures-analysis-with-r/
demo1.aov <- aov(score ~ exp_condition * ranking + Error(id), data = anova_data2)
summary(demo1.aov)


tidy_aov <- broom::tidy(demo1.aov) %>% 
    kable(col.names = c("Between-Groups or Within-Subjects",
                        "Factor",
                        "df",
                        "Sum of Squares",
                        "Mean Square",
                        "F Statistic",
                        "P Value")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")


tidy_aov

#Solution from stack overflow
#res.aov <- anova_test(
#  data = anova_data2, 
#  score ~ exp_condition * ranking,
#  wid = id
#)
#res.aov

#What's the difference between doing it the two ways above?


par(cex = .6)

with(anova_data2, interaction.plot(ranking, exp_condition, score,
  ylim = c(-1, 1), lty= c(1, 12), lwd = 3,
  ylab = "mean standardized beta", xlab = "stereotyping-projection factor", trace.label = "experimental condition"))
```

The between groups test indicates that the variable `exp_condition` is not significant, *F*(1,151) = 0.05, *p* = 0.82, and consequently in the graph we see that the lines for the two groups are overlapping. The within-subject test indicates that there is a significant effect of the within-subjects factor (stereotyping-projection); in other words, the groups change in score over time. In the graph we see that the groups have lines that have a gradual positive slope. After removing the outliers, the interaction between the stereotyping-projection factor and experimental condition approaches significance, and this can be seen as the lines start to intersect, *F*(1,151) = 2.5, *p* = 0.11.

## Summary statistics
Group the data by `exp_condition` and the repeated-measures factor (stereotyping vs. projection), and then compute some summary statistics of the `score` variable: mean and sd.

```{r, warning=FALSE, message=FALSE}
anova_data2 %>% 
  group_by(exp_condition, ranking) %>% 
  summarize(mean_score = mean(score, na.rm = TRUE),
            sd_score = sd(score, na.rm = TRUE)) %>% 
  kable(col.names = c("Experimental Condition",
                        "Repeated-Measures Factor",
                        "Mean Standardized Beta",
                      "Standard Deviation")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")


grouped_data <- anova_data2 %>% 
  group_by(exp_condition, ranking) %>% 
  summarize(mean_score = mean(score, na.rm = TRUE))

ggplot(data=grouped_data, aes(x = ranking, y = mean_score, fill = exp_condition))+
  geom_bar(stat = "identity", position = "dodge")+
  theme(axis.title.x = element_blank())+
  labs(title = "Effect of Similarity Condition on Projection and Stereotyping Constructs",
       y = "Mean Standardized Beta")

```
**Figure X**. Repeated-measures ANOVA on N = 154 (9 outliers removed from dataset).


### Create subset of open-ended data of interest to CCL

Select the following two variables of interest to the CCL team, write and save as Excel.  

- `why_advocacy`: "Why did you get involved with climate advocacy? What were the factors that led you to get involved with CCL?"  
- `feedback_ccl`: "What feedback do you have about your experience volunteering with CCL? Is it a welcoming space for you as a volunteer?"

```{r}
# Select columns of interest to Brett: `why_advocacy` and `feedback_ccl`

#why_advocacy <- ccl %>% 
#  select(response_id, why_advocacy) %>% 
#  drop_na()

#feedback_ccl <- ccl %>% 
#  select(response_id, feedback_ccl) %>% 
#  drop_na()

# Save subsets as new dataframes in the `data` subfolder

#write_xlsx(why_advocacy, here("data","why_advocacy.xlsx"))
#write_xlsx(feedback_ccl, here("data","feedback_ccl.xlsx"))

```


# Examining Zero-Order Correlations



### Zero-order correlations

How correlated overall was individual preference with Robert and stereotypical business person?  

- Can you run the correlations b/w the 3 things for each condition?  
- The below implies that when entered together, typical business was stronger predictor than self, but curious about zero order correlations. The would tell us whether there is any relationship between self-rankings and either of the other two independently.

```{r, warning=FALSE, message=FALSE}

# Adding 3 new cols. to get ready for regressions on a loop
stereotyping_projection_subset<-stereotyping_projection_subset %>% 
  rename(exp_condition = group) %>% 
  add_column(self_robert = 0) %>% # Adding 3 new cols. to get ready for regressions on a loop
  add_column(stereotype_robert = 0) %>% 
  add_column(self_stereotype = 0) 


#Calculate the multiple regressions for every participant 

# For loop will iterate through each row of the dataframe
# The scope of every action within the for loop is limited to that single iteration, so no need to manually filter data and calculate regression for each participant
for (i in 1:nrow(stereotyping_projection_subset)) {
  
  # This creates a dataframe of one row, the row that the for loop is currently on
  id<-stereotyping_projection_subset %>% 
    filter(id==stereotyping_projection_subset[[i, 1]])
  
  # This runs the linear regression using the single row created above as the dataframe
  temp_lm1 <- lm(robert_rankings ~ self_rankings, data = id)
  temp_lm2 <- lm(robert_rankings ~ stereotype_rankings, data = id)
  temp_lm3 <- lm(stereotype_rankings ~ self_rankings, data = id)
  
  # This converts the linear model object created above into an easy to read and easy to access object. This essentially cleans up the output.
  tidy_temp_lm1<-broom::tidy(temp_lm1)
  tidy_temp_lm2<-broom::tidy(temp_lm2)
  tidy_temp_lm3<-broom::tidy(temp_lm3)
  
  # This creates a variable to store the beta coefficient for self ranking predicting robert ranking for this single row
  temp_self_robert<-tidy_temp_lm1[2, 2]
  
  # This creates a variable to store the beta coefficient for stereotype ranking predicting robert ranking for this single row
  temp_stereotype_robert<-tidy_temp_lm2[2,2]
  
    # This creates a variable to store the beta coefficient for self ranking predicting stereotype ranking for this single row
  temp_self_stereotype<-tidy_temp_lm3[2,2]
  
  # The last two lines store the variables created above in columns in the original dataframe in the row that the for loop is currently on
  stereotyping_projection_subset[i, 14]<-temp_self_robert
  stereotyping_projection_subset[i, 15]<-temp_stereotype_robert
  stereotyping_projection_subset[i, 16]<-temp_self_stereotype
}

# Keep variables needed for analysis and get rid of duplicate rows
stereotyping_projection_subset <- stereotyping_projection_subset %>% 
  select(id,exp_condition,lib_con, gender_bin, normative, stereotyping, projection, projection_678, stereotyping_123, self_robert, stereotype_robert, self_stereotype) %>% 
  unique()

# Summary table of all the constructs

stereotyping_projection_subset %>% 
  group_by(exp_condition) %>% 
  summarize(mean_projection = mean(projection, na.rm = TRUE),
            mean_stereotyping = mean(stereotyping, na.rm = TRUE),
            mean_self_robert = mean(self_robert, na.rm = TRUE),
            mean_self_stereotype = mean(self_stereotype, na.rm = TRUE),
            mean_stereotype_robert = mean(stereotype_robert, na.rm = TRUE),
            mean_projection_678 = mean(projection_678, na.rm = TRUE),
            mean_stereotyping_123 = mean(stereotyping_123, na.rm = TRUE)) %>% 
  kable(col.names = c("Experimental Condition",
                      "Mean Projection (Std. Beta)",
                      "Mean Stereotyping (Std. Beta)",
                        "Mean Self-Robert Correlation",
                        "Mean Self-Stereotype Correlation",
                      "Mean Stereotype-Robert Correlation",
                      "Mean Use of (Self) Reasons 6,7,8 for Robert",
                      "Mean Use of (Business-y) Reasons 1,2,3 for Robert")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```


From this table, it appears that in the **Different** condition, participants had a stronger negative correlation between self and Robert than in the **Similar** condition (although the relationships were close to zero for both, i.e. no relationship). For everyone, the self-stereotype correlation was a weak negative correlation (the experimental condition happened after this so it would not affect differences in the correlations). For everyone, the relationship between stereotype and Robert was strong and positive. 

### Visualize the distributions of the zero-order correlations:

```{r}
hist(stereotyping_projection_subset$self_robert)
hist(stereotyping_projection_subset$self_stereotype)
hist(stereotyping_projection_subset$stereotype_robert)
```

- As shown in the summary table above, across conditions, the mode (and median) correlation for self-robert was close to zero. In other words, participants' ratings for themselves had no relationship to their ratings for Robert. 
- Across conditions, participants' ratings for self appear to be weakly negatively related to their ratings for the typical businessman (the mode is around -.75, the median around -0.18).  
- **This is interesting**: it seems that being "introduced" to Robert as a conversation partner, regardless of whether he was manipulated to be similar or different, seems to pull participants away from the stereotype quite a bit.
- Across conditions, participants' ratings for the typical businessman are strongly positively correlated to their ratings for Robert (the median is around 0.5, but the mode is in the .75 to 1.0 bin)


### Examine top 2-3 rankings for self, typical businessman, for Robert

Also - did you look at what people chose as the top 2-3 ones for self for business, for Robert? Does it seem as though people were responding reasonably and differently to the prompts?

As shown below (and reinforcing the results we saw in the zero-order correlations), participants respond almost the same when ranking reasons for typical businessman and for Robert.

```{r, warning = FALSE, message=FALSE}
top_reasons <- ccl_long %>% 
  select(id,reason_number,group,s,g,r) %>% 
  rename(self_rankings = s,
         stereotype_rankings = g,
         robert_rankings = r)

mean_freq_self <- top_reasons %>% 
  group_by(reason_number) %>% 
  summarize(mean_self_ranking = mean(self_rankings))

mean_freq_stereotype<- top_reasons %>% 
  group_by(reason_number) %>% 
  summarize(mean_stereotype_ranking = mean(stereotype_rankings))

mean_freq_robert<- top_reasons%>% 
  group_by(reason_number) %>% 
  summarize(mean_robert_ranking = mean(robert_rankings))

ggplot(data = mean_freq_self, aes(x = reason_number, y = mean_self_ranking))+
  geom_bar(stat = "identity")+
  labs(x = "Reason Number",
       y = "Mean Ranking",
       title = "On Average, Participants' Top Reasons for Self are 7, 8, 6")+
  theme_minimal()

ggplot(data = mean_freq_stereotype, aes(x = reason_number, y = mean_stereotype_ranking))+
  geom_bar(stat = "identity")+
    labs(x = "Reason Number",
       y = "Mean Ranking",
       title = "On Average, Participants' Top Reasons for Typical Businessman are 2, 3, 1")+
  theme_minimal()

ggplot(data = mean_freq_robert, aes(x = reason_number, y = mean_robert_ranking))+
  geom_bar(stat = "identity")+
      labs(x = "Reason Number",
       y = "Mean Ranking",
       title = "On Average, Participants' Top Reasons for Robert are 2, 3, 1")+
  theme_minimal()

```


- For **self**, participants ranked reasons 7 ("It will keep the Earth from warming more than 1.5 degrees Celsius above pre-industrial levels, at which point irreversible damages to our planet - including polar ice sheet collapse, disease, and famines - would occur"), 8 ("It will be a crucial step in mitigating the climate crisis that we have caused and therefore have the responsibility to solve."), 6 ("It will ensure that we leave behind a safe and habitable planet for future generations to enjoy.") as most important on average.  
- For **stereotype**, participants ranked reasons 2 ("It will create a demand for local jobs and boost local economies as American families spend their monthly carbon dividends in their communities."), 3 ("It will prevent communities and local businesses from losing billions of dollars on damages caused by climate-change related disasters."), 1 ("It will drive innovation and put our country on the forefront of a transition to a clean energy economy.") as most important on average.  
- For **Robert**, participants ranked reasons 2, 3, 1 as most important on average.  

# T-tests with Zero-Order Correlations

DS notes: There are 2 ways to look at stereotyping and projection: the MLR beta way, which looks at the *relative* importance of each, or the correlational way, which looks at how the independent impact of each rating differs between conditions. 

Put original MLR beta analyses in primary results section, put correlational analyses as footnote. Do independent samples t-tests for zero-order correlations for self-robert and stereotype-robert to see if they significantly differ between exp condition:

**NOTE**: Not necessary to look at effect of condition on self-stereotype because Ss received the experiment AFTER completing rankings for self and stereotype.

**QUESTION**: Should I remove outliers before all of these analyses?

### Independent samples t-tests on zero-order

- Effect of experimental condition on correlation between self-robert: N.S., *p* = 0.54  
- Effect of experimental condition on correlation between stereotype-Robert: N.S., *p* = 0.21

```{r, message=FALSE, warning=FALSE}
# Compute independent samples t-test of self_robert predicted by exp_condition 
res <- t.test(self_robert ~ exp_condition, data = stereotyping_projection_subset, var.equal = TRUE)
#res # N.S., p = 0.54

# Compute independent samples t-test of stereotype_robert predicted by exp_condition 
res2 <- t.test(stereotype_robert~ exp_condition, data = stereotyping_projection_subset, var.equal = TRUE)
#res2 # N.S., p = 0.21

```

## One-sample t-tests on zero-order

Do one-sample t-tests for all 3 zero-order correlations to see if they significantly differ from zero. one sample t-test "evidence that the stereotyping is significantly different from zero, and by how much?"  
- `self_robert`: *t*(1,160) = -648.45, *p* < .0001, d = -51.10 (large)  
- `self_stereotype`: *t*(1,160) = -611.97, *p* < .0001, d = -48.23 (large)  
- `stereotype_robert`: *t*(1,161) = -810.28, *p* < .0001, d = -63.86 (large)   
There is evidence that the zero-order relationships between self-robert, self-stereotype, and stereotype-robert significantly differ from zero. 

```{r,message=FALSE,warning=FALSE}
#One sample t-test on self_robert
ttest1 <- stereotyping_projection_subset %>% 
  t_test(self_robert ~ 1, mu = 25)
#ttest1
#stereotyping_projection_subset %>% 
# cohens_d(self_robert ~ 1, mu = 25)

#One sample t-test on self_stereotype
ttest2 <- stereotyping_projection_subset %>% 
  t_test(self_stereotype ~ 1, mu = 25)
#ttest2
#stereotyping_projection_subset %>% 
#  cohens_d(self_stereotype ~ 1, mu = 25)

#One sample t-test on stereotype_robert
ttest3 <- stereotyping_projection_subset %>% 
  t_test(stereotype_robert ~ 1, mu = 25)
#ttest3
#stereotyping_projection_subset %>% 
 # cohens_d(stereotype_robert ~ 1, mu = 25)
```

## Gender differences on zero-order
Do 2x2 ANOVA with M/F vs. Similar/Diff on projection and stereotyping, and on zero-order correlations as well.  

On projection and stereotyping: 

- Effect of gender and condition on **projection**: N.S. interaction, *p* = .66. But INTERESTING - the effect of gender on projection approaches significance, *F*(1,156) = 2.58, *p* = .11. I followed this up with an independent samples t-test looking at the effect of gender alone on projection: approaches significance, *t*(1,158) = -1.62, *p* = .11 (Female *M* = .017, Male *M* = .13). So looks like males feel more similar to Robert than females and they project more.
- Effect of gender and condition on **stereotyping**: N.S. interaction, *p* = .66. N.S. effect of gender, *p* = .93.  

On zero-order correlations (again, doesn't make sense to look at self-stereotype because experiment happened after participants ranked for both self and stereotypical businessman):  

- `self_robert`: N.S. interaction, *p* = .40, but the effect of gender on the relationship between self and robert is significant, *F*(1,157) = 6.511, *p* = .01. I followed this up with an independent samples t-test looking at the effect of gender alone on `self_robert`: significant, *t*(1,158) = -2.56, *p* = .01 (Female *M* = -.17, Male *M* = .03). Converges with the result on projection above.  
- `stereotype_robert`: N.S. interaction, *p* = .77, N.S. effect of gender, *p* = 17.

```{r, message=FALSE,warning=FALSE}
# identify outliers
#stereotyping_projection_subset %>% 
 # group_by(exp_condition, gender_bin) %>% 
#  identify_outliers(projection)

#stereotyping_projection_subset %>% 
#  group_by(exp_condition, gender_bin) %>% 
#  identify_outliers(stereotyping)

#stereotyping_projection_subset %>% 
#  group_by(exp_condition, gender_bin) %>% 
#  identify_outliers(projection_678)

#stereotyping_projection_subset %>% 
#  group_by(exp_condition, gender_bin) %>% 
#  identify_outliers(stereotyping_123)

# Should I remove outliers?


# Projection and Stereotyping:

#Two-way anova: Gender (M/F) and Condition (Sim/Diff) on projection:
res.aov1 <- aov(projection ~ gender_bin + exp_condition + gender_bin:exp_condition, data = stereotyping_projection_subset)
#summary(res.aov1)
#Do a t-test to follow up:
gender_projection <- t.test(projection ~ gender_bin, data = stereotyping_projection_subset, var.equal = TRUE)
#gender_projection

#Two-way anova: Gender (M/F) and Condition (Sim/Diff) on stereotyping:
res.aov2 <- aov(stereotyping ~ gender_bin + exp_condition + gender_bin:exp_condition, data = stereotyping_projection_subset)
#summary(res.aov2)


# Zero-order variables:

#Two-way anova: Gender (M/F) and Condition (Sim/Diff) on self-robert:
res.aov3 <- aov(self_robert ~ gender_bin + exp_condition + gender_bin:exp_condition, data = stereotyping_projection_subset)
#summary(res.aov3)
#Do a t-test to follow up:
gender_self_robert<- t.test(self_robert ~ gender_bin, data = stereotyping_projection_subset, var.equal = TRUE)
#gender_self_robert


#Two-way anova: Gender (M/F) and Condition (Sim/Diff) on stereotype_robert:
res.aov5 <- aov(stereotype_robert ~ gender_bin + exp_condition + gender_bin:exp_condition, data = stereotyping_projection_subset)
#summary(res.aov5)

```


## Liberal vs. conservative differences: projection and stereotyping, and zero-order
Do 2x2 ANOVA with Libs/Mods + Cons vs. Similar/Diff on projection and stereotyping, and on zero-order correlations as well

On projection and stereotyping: 

- Effect of lib_con and condition on **projection**: interaction approaches significance, *F*(1,152) = 2.85, *p* = .09, N.S. main effect *p* = .22
- Effect of lib_con and condition on **stereotyping**: interaction approaches significance, *F*(1,151) = 3.36, *p* = .07, N.S. main effect *p* = .79 

On zero-order correlations (again, doesn't make sense to look at self-stereotype because experiment happened after participants ranked for both self and stereotypical businessman):  

- `self_robert`: significant interaction, *F*(1,152) = 5.59, *p* = .02, N.S. main effect *p* = .10
- `stereotype_robert`: significant interaction, *F*(1,152) = 7.85, *p* = .006, N.S. main effect *p* = .87 

```{r, message=FALSE, warning=FALSE}

# Projection and Stereotyping:

#Two-way anova: lib_con (lib vs. con) and Condition (Sim/Diff) on projection:
libcon1 <- aov(projection ~ lib_con + exp_condition + lib_con:exp_condition, data = stereotyping_projection_subset)
#summary(libcon1)

#Two-way anova: lib_con (lib vs. con)  and Condition (Sim/Diff) on stereotyping:
libcon2 <- aov(stereotyping ~ lib_con  + exp_condition + lib_con:exp_condition, data = stereotyping_projection_subset)
#summary(libcon2)


# Zero-order variables:

#Two-way anova: lib_con and Condition (Sim/Diff) on self-robert:
libcon3 <- aov(self_robert ~ lib_con + exp_condition + lib_con:exp_condition, data = stereotyping_projection_subset)
#summary(libcon3)

#Two-way anova: lib_con and Condition (Sim/Diff) on stereotype_robert:
libcon4 <- aov(stereotype_robert ~ lib_con  + exp_condition + lib_con:exp_condition, data = stereotyping_projection_subset)
#summary(libcon4)

grouped_dvs_libcon <- stereotyping_projection_subset %>% 
  group_by(lib_con, exp_condition) %>% 
  summarize(mean_projection = mean(projection),
            mean_stereotyping = mean(stereotyping, na.rm = TRUE),
            mean_self_robert = mean(self_robert),
            mean_stereotype_robert = mean(stereotype_robert)) %>% 
  drop_na()

grouped_dvs_libcon %>% 
     kable(col.names = c("Political Ideology",
                      "Similarity Condition",
                      "Mean Projection",
                      "Mean Stereotyping",
                      "Mean Self-Robert",
                      "Mean Stereotype-Robert")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

```

### Visualize the lib_con * exp_condition interaction

#### On projection

Looks like the experimental condition only makes a difference on liberals. Conservatives project more in the difference condition?
```{r, message=FALSE, warning=FALSE}

# On projection
ggplot(data=grouped_dvs_libcon, aes(x = lib_con, y = mean_projection, fill = exp_condition))+
  geom_bar(stat = "identity", position = "dodge")+
  theme(axis.title.x = element_blank())+
  labs(title = "Effect of Similarity Condition and Lib/Con on Projection",
       y = "Mean Standardized Beta")


```

#### On stereotyping

Liberals stereotype more in the difference condition, conservatives stereotype more in the similarity condition

```{r, message=FALSE, warning=FALSE}
#Visualize the lib_con * exp_condition interaction on stereotyping

# On stereotyping
ggplot(data=grouped_dvs_libcon, aes(x = lib_con, y = mean_stereotyping, fill = exp_condition))+
  geom_bar(stat = "identity", position = "dodge")+
  theme(axis.title.x = element_blank())+
  labs(title = "Effect of Similarity Condition and Lib/Con on Stereotyping",
       y = "Mean Standardized Beta")

```


# Alternative DV: averages of 'enviro' reasons and 'businessman' reasons

Content of reasons: the average of reasons 6,7,8 (the consensual long-term sustainability reasons) and 1,2,3 (the consensual businessman reasons) can serve as alternative primary DVs.  

Do some simple t-tests: Is the average of 6,7,8 different for Robert in the similarity vs. difference conditions?
Is the average of 2,3,1 higher for Robert in the similarity vs. difference conditions?

- Effect of experimental condition on use of self reasons (6,7,8, alpha = .48) for Robert: N.S., *p* = 0.13
- Effect of experimental condition on use of business-y reasons (1,2,3, alpha = .46) for Robert: N.S., *p* = 0.28

```{r, message=FALSE, warning=FALSE}
# Effect of exp condition on projection_678
aov678 <- t.test(projection_678~ exp_condition, data = stereotyping_projection_subset, var.equal = TRUE)
#aov678 # N.S., p = 0.13

# Effect of exp condition on stereotyping_123
aov123 <- t.test(stereotyping_123~ exp_condition, data = stereotyping_projection_subset, var.equal = TRUE)
#aov123 # N.S., p = 0.28
```

Mixed-model ANOVA: look at average ratings of 1,2,3 vs. 6,7,8 in the 2 conditions:

**Note**: IDK if a mixed-model makes sense for this because the alt. DVs  were only calculated at 1 time point (aka the averages of Ss's ranking 6,7,8 or 1,2,3 for Robert, not repeated-measures)

Interaction approaches significance, *F*(1,159) = 1.88, *p* = .17 

```{r, message=FALSE, warning=FALSE}
anova_data3 <- stereotyping_projection_subset %>% 
  gather(key = "ranking", value = "score", projection_678, stereotyping_123) %>% 
  convert_as_factor(id, ranking) %>% 
  unique() %>% 
  mutate(exp_condition = as_factor(exp_condition))  


mixed_aov <- aov(score ~ exp_condition * ranking + Error(id), data = anova_data3)
#summary(mixed_aov)


tidy_aov2 <- broom::tidy(mixed_aov) %>% 
    kable(col.names = c("Between-Groups or Within-Subjects",
                        "Factor",
                        "df",
                        "Sum of Squares",
                        "Mean Square",
                        "F Statistic",
                        "P Value")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

tidy_aov2

par(cex = .6)

with(anova_data3, interaction.plot(ranking, exp_condition, score,
  ylim = c(1, 8), lty= c(1, 12), lwd = 3,
  ylab = "mean scores", xlab = "stereotyping-projection factor", trace.label = "experimental condition"))
```




## Gender differences on alt DVs

Do 2x2 ANOVA with M/F vs. Similar/Diff on 6,7,8 and 1,2,3  
- `projection_678`: N.S. interaction, *p* = .78  
- `stereotyping_123`: N.S. interaction, *p* = .96

```{r, message=FALSE, warning=FALSE}

#Two-way anova: Gender (M/F) and Condition (Sim/Diff) on projection_678:
alt_dv_projection <- aov(projection_678 ~ gender_bin + exp_condition + gender_bin:exp_condition, data = stereotyping_projection_subset)
#summary(alt_dv_projection)

#Two-way anova: Gender (M/F) and Condition (Sim/Diff) on stereotyping_123:
alt_dv_stereotyping <- aov(stereotyping_123 ~ gender_bin + exp_condition + gender_bin:exp_condition, data = stereotyping_projection_subset)
#summary(alt_dv_stereotyping)

```




## Liberal vs. conservative differences on alt DVs

Do 2x2 ANOVA with Libs/Mods + Cons vs. Similar/Diff on 6,7,8 and 1,2,3  

- `projection_678`: significant interaction, *F*(1,152) = 3.82, *p* = .052 
- `stereotyping_123`: significant interaction, *F*(1,152) = 4.105, *p* = .045

```{r, message=FALSE, warning=FALSE}
#Two-way anova: lib_con and Condition (Sim/Diff) on projection_678:
alt_dv_projection_libcon <- aov(projection_678 ~ lib_con + exp_condition + lib_con:exp_condition, data = stereotyping_projection_subset)
#summary(alt_dv_projection_libcon)

#Two-way anova: lib_con and Condition (Sim/Diff) on stereotyping_123:
alt_dv_stereotyping_libcon <- aov(stereotyping_123 ~ lib_con + exp_condition + lib_con:exp_condition, data = stereotyping_projection_subset)
#summary(alt_dv_stereotyping_libcon)

```




# Exploratory: Normative vs. Non-normative on alt DVs 

Code participants as concordant or non-concordant with the predominant social norm (in this population, they like camping, adventurous vacation, don't like scary movies). If they had 0 or 1 attributes that are most common, they are non-concordant; if 3, they are concordant.  

Does splitting people into normative on 3's or 0s affect the way that they respond to the similarity manipulation? Do a 2x2 ANOVA. 

- on `projection_678`: N.S. interaction, *p* = .15  
- on `stereotyping_123`: interaction approaches significance, *p* = .07
```{r, message=FALSE, warning=FALSE}
#Two-way anova: normative and Condition (Sim/Diff) on projection_678:
normative <- aov(projection_678 ~ normative + exp_condition + normative:exp_condition, data = stereotyping_projection_subset)
#summary(normative)

#Two-way anova: normative and Condition (Sim/Diff) on stereotyping_123:
normative1 <- aov(stereotyping_123 ~ normative + exp_condition + normative:exp_condition, data = stereotyping_projection_subset)
#summary(normative1)


```


### Visualize normative vs. non-normative * experimental condition on alt DVs

```{r, message=FALSE, warning=FALSE}
normative_grouped <- stereotyping_projection_subset %>% 
  group_by(normative, exp_condition) %>% 
  summarise(mean_projection_678 = mean(projection_678, na.rm = TRUE),
            mean_stereotyping_123 = mean(stereotyping_123, na.rm = TRUE)) %>% 
  drop_na()



```

#### On alt DV of projection: 

```{r}
ggplot(data=normative_grouped, aes(x = normative, y = mean_projection_678, fill = exp_condition))+
  geom_bar(stat = "identity", position = "dodge")+
  theme(axis.title.x = element_blank())+
  labs(title = "Effect of Experimental Condition and Norm/Non-Norm on Projection",
       y = "Average of reasons 6,7,8 for Robert")

```

#### On alt DV of stereotyping:

```{r}
ggplot(data=normative_grouped, aes(x = normative, y = mean_stereotyping_123, fill = exp_condition))+
  geom_bar(stat = "identity", position = "dodge")+
  theme(axis.title.x = element_blank())+
  labs(title = "Effect of Experimental Condition and Norm/Non-Norm on Stereotyping",
       y = "Average of reasons 1,2,3 for Robert")
```




