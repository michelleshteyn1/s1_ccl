---
title: 'S1 CCL: Final Results for Manuscript'
author: "Michelle Shteyn Handy"
date: "5/3/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide 
---

```{r setup, include=FALSE}

#Attach packages
library(tidyverse)
library(here)
library(lubridate)
library(janitor)
library(kableExtra)
library(ggpubr)
library(rstatix)
library(psych)
library(nlme)
library(emmeans)
library(forcats)
```


# Read in data and initial wrangling

## Delete all piloting 

- The study was conducted from March 12, 2021 to April 1, 2021  
- Delete anyone before 03-12-2021  
- Delete duplicate IP addresses  
- We recruited 200 people from a list of 5000 CCL members. **286 individuals** participated in the study (this includes those who started it but did not complete it, their data was recorded)


```{r, warning=FALSE, message=FALSE}

# Read in data
ccl <- read_csv(here::here("data","s1_ccl_2021-4-2.csv"))

# Delete anyone before the survey launched (3-12-2021) 
ccl <- ccl[-c(1:2),] %>%
  separate(StartDate, c("date","time"), sep = " ") %>%  
  mutate(date = ymd(date)) %>%  
  filter(date >= as.Date("2021-03-12")) %>%  
  filter(Status != "Survey Preview") %>% # Delete any survey previews (there was 1)
  filter(ResponseId != "R_3e2HW1XRAHaDuSv") %>%  # Remove David's response 
  clean_names() %>% 
  mutate(progress = as.numeric(progress), 
         duration_in_seconds = as.numeric(duration_in_seconds),
         duration_in_minutes = duration_in_seconds/60) %>% 
  rename(exp_condition = group)
```

## Data cleaning

- Delete progress < 90%  (108 people)
- Delete anyone else who took survey in less than 5 min (6 people) or more than 120 minutes (11 people)  
- 14 people got removed from the Different condition, 9 from Similar, 102 didn't take the survey long enough to get assigned a condition
- After removing 125 individuals based on the exclusion criteria, **161 individuals** were included in analyses

```{r, warning=FALSE, message=FALSE}
# Create a new 'remove' variable using an if-else statement
ccl <- ccl %>% 
  mutate(remove = ifelse(duration_in_minutes >= 5 & duration_in_minutes <= 120 & progress >= 90, "Keep", "Remove"))

#14 people got removed from the Different condition, 9 from Similar, 102 didn't take the survey long enough to get assigned a condition
#ccl %>% 
#  group_by(remove, exp_condition) %>% 
 # summarise(counts = n())

#this confirms 125 people got removed
ccl <- ccl %>% 
  filter(progress >= 90) %>% 
  filter(duration_in_minutes >= 5) %>% 
  filter(duration_in_minutes <= 120)

# Create a new row called `id` which assigns each Ss an ID number based on the row they are in
ccl<- ccl %>% 
  mutate(id = row_number()) 

```


# Calculating constructs

## Reverse code ranking items

Higher scores indicate greater importance/persuasiveness of that reason.

```{r, warning=FALSE, message=FALSE}

# Reverse code self ranking items

ccl <- ccl %>% 
  mutate(s1 = case_when(
                   self_1 == 1 ~ 8, 
                   self_1 == 2 ~ 7, 
                   self_1 == 3 ~ 6, 
                   self_1 == 4 ~ 5, 
                   self_1 == 5 ~ 4,
                   self_1 == 6 ~ 3, 
                   self_1 == 7 ~ 2,
                   self_1 == 8 ~ 1),
         s2 = case_when(
                   self_2 == 1 ~ 8, 
                   self_2 == 2 ~ 7, 
                   self_2 == 3 ~ 6, 
                   self_2 == 4 ~ 5, 
                   self_2 == 5 ~ 4,
                   self_2 == 6 ~ 3, 
                   self_2 == 7 ~ 2,
                   self_2 == 8 ~ 1),
         s3 = case_when(
                   self_3 == 1 ~ 8, 
                   self_3 == 2 ~ 7, 
                   self_3 == 3 ~ 6, 
                   self_3 == 4 ~ 5, 
                   self_3 == 5 ~ 4,
                   self_3 == 6 ~ 3, 
                   self_3 == 7 ~ 2,
                   self_3 == 8 ~ 1),
         s4 = case_when(
                   self_4 == 1 ~ 8, 
                   self_4 == 2 ~ 7, 
                   self_4 == 3 ~ 6, 
                   self_4 == 4 ~ 5, 
                   self_4 == 5 ~ 4,
                   self_4 == 6 ~ 3, 
                   self_4 == 7 ~ 2,
                   self_4 == 8 ~ 1),
         s5 = case_when(
                   self_5 == 1 ~ 8, 
                   self_5 == 2 ~ 7, 
                   self_5 == 3 ~ 6, 
                   self_5 == 4 ~ 5, 
                   self_5 == 5 ~ 4,
                   self_5 == 6 ~ 3, 
                   self_5 == 7 ~ 2,
                   self_5 == 8 ~ 1),
         s6 = case_when(
                  self_6 == 1 ~ 8, 
                   self_6 == 2 ~ 7, 
                   self_6 == 3 ~ 6, 
                   self_6 == 4 ~ 5, 
                   self_6 == 5 ~ 4,
                   self_6 == 6 ~ 3, 
                   self_6 == 7 ~ 2,
                   self_6 == 8 ~ 1),
         s7 = case_when(
                   self_7 == 1 ~ 8, 
                   self_7 == 2 ~ 7, 
                   self_7 == 3 ~ 6, 
                   self_7 == 4 ~ 5, 
                   self_7 == 5 ~ 4,
                   self_7 == 6 ~ 3, 
                   self_7 == 7 ~ 2,
                   self_7 == 8 ~ 1),
         s8 = case_when(
                   self_8 == 1 ~ 8, 
                   self_8 == 2 ~ 7, 
                   self_8 == 3 ~ 6, 
                   self_8 == 4 ~ 5, 
                   self_8 == 5 ~ 4,
                   self_8 == 6 ~ 3, 
                   self_8 == 7 ~ 2,
                   self_8 == 8 ~ 1))

# Reverse code stereotype ranking items

ccl <- ccl %>% 
  mutate(g1 = case_when(
                   stereotype_1 == 1 ~ 8, 
                   stereotype_1 == 2 ~ 7, 
                   stereotype_1 == 3 ~ 6, 
                   stereotype_1 == 4 ~ 5, 
                   stereotype_1 == 5 ~ 4,
                   stereotype_1 == 6 ~ 3, 
                   stereotype_1 == 7 ~ 2,
                   stereotype_1 == 8 ~ 1),
         g2 = case_when(
                   stereotype_2 == 1 ~ 8, 
                   stereotype_2 == 2 ~ 7, 
                   stereotype_2 == 3 ~ 6, 
                   stereotype_2 == 4 ~ 5, 
                   stereotype_2 == 5 ~ 4,
                   stereotype_2 == 6 ~ 3, 
                   stereotype_2 == 7 ~ 2,
                   stereotype_2 == 8 ~ 1),
         g3 = case_when(
                   stereotype_3 == 1 ~ 8, 
                   stereotype_3 == 2 ~ 7, 
                   stereotype_3 == 3 ~ 6, 
                   stereotype_3 == 4 ~ 5, 
                   stereotype_3 == 5 ~ 4,
                   stereotype_3 == 6 ~ 3, 
                   stereotype_3 == 7 ~ 2,
                   stereotype_3 == 8 ~ 1),
         g4 = case_when(
                   stereotype_4 == 1 ~ 8, 
                   stereotype_4 == 2 ~ 7, 
                   stereotype_4 == 3 ~ 6, 
                   stereotype_4 == 4 ~ 5, 
                   stereotype_4 == 5 ~ 4,
                   stereotype_4 == 6 ~ 3, 
                   stereotype_4 == 7 ~ 2,
                   stereotype_4 == 8 ~ 1),
         g5 = case_when(
                   stereotype_5 == 1 ~ 8, 
                   stereotype_5 == 2 ~ 7, 
                   stereotype_5 == 3 ~ 6, 
                   stereotype_5 == 4 ~ 5, 
                   stereotype_5 == 5 ~ 4,
                   stereotype_5 == 6 ~ 3, 
                   stereotype_5 == 7 ~ 2,
                   stereotype_5 == 8 ~ 1),
         g6 = case_when(
                  stereotype_6 == 1 ~ 8, 
                   stereotype_6 == 2 ~ 7, 
                   stereotype_6 == 3 ~ 6, 
                   stereotype_6 == 4 ~ 5, 
                   stereotype_6 == 5 ~ 4,
                   stereotype_6 == 6 ~ 3, 
                   stereotype_6 == 7 ~ 2,
                   stereotype_6 == 8 ~ 1),
         g7 = case_when(
                   stereotype_7 == 1 ~ 8, 
                   stereotype_7 == 2 ~ 7, 
                   stereotype_7 == 3 ~ 6, 
                   stereotype_7 == 4 ~ 5, 
                   stereotype_7 == 5 ~ 4,
                   stereotype_7 == 6 ~ 3, 
                   stereotype_7 == 7 ~ 2,
                   stereotype_7 == 8 ~ 1),
         g8 = case_when(
                   stereotype_8 == 1 ~ 8, 
                   stereotype_8 == 2 ~ 7, 
                   stereotype_8 == 3 ~ 6, 
                   stereotype_8 == 4 ~ 5, 
                   stereotype_8 == 5 ~ 4,
                   stereotype_8 == 6 ~ 3, 
                   stereotype_8 == 7 ~ 2,
                   stereotype_8 == 8 ~ 1))

# Reverse code robert ranking items

ccl <- ccl %>% 
  mutate(r1 = case_when(
                   robert_1 == 1 ~ 8, 
                   robert_1 == 2 ~ 7, 
                   robert_1 == 3 ~ 6, 
                   robert_1 == 4 ~ 5, 
                   robert_1 == 5 ~ 4,
                   robert_1 == 6 ~ 3, 
                   robert_1 == 7 ~ 2,
                   robert_1 == 8 ~ 1),
         r2 = case_when(
                   robert_2 == 1 ~ 8, 
                   robert_2 == 2 ~ 7, 
                   robert_2 == 3 ~ 6, 
                   robert_2 == 4 ~ 5, 
                   robert_2 == 5 ~ 4,
                   robert_2 == 6 ~ 3, 
                   robert_2 == 7 ~ 2,
                   robert_2 == 8 ~ 1),
         r3 = case_when(
                   robert_3 == 1 ~ 8, 
                   robert_3 == 2 ~ 7, 
                   robert_3 == 3 ~ 6, 
                   robert_3 == 4 ~ 5, 
                   robert_3 == 5 ~ 4,
                   robert_3 == 6 ~ 3, 
                   robert_3 == 7 ~ 2,
                   robert_3 == 8 ~ 1),
         r4 = case_when(
                   robert_4 == 1 ~ 8, 
                   robert_4 == 2 ~ 7, 
                   robert_4 == 3 ~ 6, 
                   robert_4 == 4 ~ 5, 
                   robert_4 == 5 ~ 4,
                   robert_4 == 6 ~ 3, 
                   robert_4 == 7 ~ 2,
                   robert_4 == 8 ~ 1),
         r5 = case_when(
                   robert_5 == 1 ~ 8, 
                   robert_5 == 2 ~ 7, 
                   robert_5 == 3 ~ 6, 
                   robert_5 == 4 ~ 5, 
                   robert_5 == 5 ~ 4,
                   robert_5 == 6 ~ 3, 
                   robert_5 == 7 ~ 2,
                   robert_5 == 8 ~ 1),
         r6 = case_when(
                  robert_6 == 1 ~ 8, 
                   robert_6 == 2 ~ 7, 
                   robert_6 == 3 ~ 6, 
                   robert_6 == 4 ~ 5, 
                   robert_6 == 5 ~ 4,
                   robert_6 == 6 ~ 3, 
                   robert_6 == 7 ~ 2,
                   robert_6 == 8 ~ 1),
         r7 = case_when(
                   robert_7 == 1 ~ 8, 
                   robert_7 == 2 ~ 7, 
                   robert_7 == 3 ~ 6, 
                   robert_7 == 4 ~ 5, 
                   robert_7 == 5 ~ 4,
                   robert_7 == 6 ~ 3, 
                   robert_7 == 7 ~ 2,
                   robert_7 == 8 ~ 1),
         r8 = case_when(
                   robert_8 == 1 ~ 8, 
                   robert_8 == 2 ~ 7, 
                   robert_8 == 3 ~ 6, 
                   robert_8 == 4 ~ 5, 
                   robert_8 == 5 ~ 4,
                   robert_8 == 6 ~ 3, 
                   robert_8 == 7 ~ 2,
                   robert_8 == 8 ~ 1))

```

## Explore reason rankings

### Examine top 2-3 rankings for self, typical businessman, for Robert

For **self**, participants ranked reasons 7, 8, and 6 as most important on average:

- 7: "It will keep the Earth from warming more than 1.5 degrees Celsius above pre-industrial levels, at which point irreversible damages to our planet - including polar ice sheet collapse, disease, and famines - would occur"  
- 8: "It will be a crucial step in mitigating the climate crisis that we have caused and therefore have the responsibility to solve."  
- 6: "It will ensure that we leave behind a safe and habitable planet for future generations to enjoy."

For **stereotype**, participants ranked reasons 2, 3, and 1 as most important on average:  

- 2: "It will create a demand for local jobs and boost local economies as American families spend their monthly carbon dividends in their communities."   
- 3: "It will prevent communities and local businesses from losing billions of dollars on damages caused by climate-change related disasters."    
- 1: "It will drive innovation and put our country on the forefront of a transition to a clean energy economy."

For **Robert**, participants ranked reasons 2, 3, and 1 as most important on average. 


```{r, message=FALSE, warning=FALSE}

# Use `pivot_longer()` to make the data tidy and have variables for: reason_number, self_rankings, stereotype_rankings, robert_rankings
ccl_long <- ccl %>% 
  pivot_longer(
    cols = s1:r8,
    names_to = c(".value","reason_number"),
    names_pattern = "(.)(.)",
    values_drop_na = TRUE
  )

top_reasons <- ccl_long %>% 
  select(id,reason_number,exp_condition,s,g,r) %>% 
  rename(self_rankings = s,
         stereotype_rankings = g,
         robert_rankings = r)

mean_freq_self <- top_reasons %>% 
  group_by(reason_number) %>% 
  summarize(mean_self_ranking = mean(self_rankings))

mean_freq_stereotype<- top_reasons %>% 
  group_by(reason_number) %>% 
  summarize(mean_stereotype_ranking = mean(stereotype_rankings))

mean_freq_robert<- top_reasons%>% 
  group_by(reason_number) %>% 
  summarize(mean_robert_ranking = mean(robert_rankings))

```


## Create binary variables

Create 3 binary variables:

- `gender_bin` (Male/Female)  
- `lib_con` (Liberal = Very liberal, liberal; Conservative = Moderate, Conservative, & Very conservative)
- `dem_rep` (Democrat = Strong Democrat, Not Very Strong Democrat, Closer to Democratic Party; Republican = Closer to Republican Party, Not Very Strong Republican, Strong Republican)  


Create numeric variables:  

- Create `lib_con_num`, a numeric version of `ideology` from 1 (Very Liberal) to 5 (Very Conservative).  
- Create `pol_7_pt`, which consolidates the branching dem/rep questions into 1 (Strong Democrat) to 7 (Strong Republican).

```{r, message=FALSE, warning=FALSE}

# First, put branching dem/rep into 1 variable

#numeric dem/rep variable
ccl <- ccl %>% 
  mutate(pol_7_pt = case_when(
    dem_strong_weak == "Strong Democrat" ~ 1,
    dem_strong_weak == "Not Very Strong Democrat" ~ 2, 
    closer_dem_rep == "Closer to Democratic Party" ~ 3,
    closer_dem_rep == "Neither" ~ 4,
    closer_dem_rep == "Closer to Republican Party" ~ 5, 
    rep_strong_weak == "Not Very Strong Republican" ~ 6,
    rep_strong_weak == "Strong Republican" ~ 7
  ))

#mean(ccl$pol_7_pt) 

#character dem/rep
ccl <- ccl %>% 
  mutate(pol_7_pt_char = case_when(
    dem_strong_weak == "Strong Democrat" ~ "Strong Democrat",
    dem_strong_weak == "Not Very Strong Democrat" ~ "Not Very Strong Democrat", 
    closer_dem_rep == "Closer to Democratic Party" ~ "Closer to Democratic Party",
    closer_dem_rep == "Neither" ~ "Neither",
    closer_dem_rep == "Closer to Republican Party" ~ "Closer to Republican Party", 
    rep_strong_weak == "Not Very Strong Republican" ~ "Not Very Strong Republican",
    rep_strong_weak == "Strong Republican" ~ "Strong Republican"
  ))


ccl <- ccl %>% 
  mutate(gender_bin = case_when(
    gender=="Female"~"Female",
    gender=="Male"~"Male"),
  gender_bin = as.factor(gender_bin), # Make sure `gender_bin` is a factor variable
  gender_bin = fct_drop(gender_bin),  # Drop unused factor levels
   lib_con = case_when(
    ideology=="Very liberal"~"Liberal",
    ideology=="Liberal"~"Liberal",
    ideology=="Moderate"~"Moderate/Conservative",
    ideology=="Conservative"~"Moderate/Conservative",
    ideology=="Very conservative"~"Moderate/Conservative"),
  lib_con = as.factor(lib_con), # Make sure `lib_con` is a factor variable
  lib_con = fct_drop(lib_con),  # Drop unused factor levels
  lib_con_num = case_when(
    ideology=="Very liberal"~ 1,
    ideology=="Liberal"~ 2,
    ideology=="Moderate"~ 3,
    ideology=="Conservative"~ 4,
    ideology=="Very conservative"~ 5),
   lib_con_num = as.numeric(lib_con_num),
dem_rep = case_when(
    pol_7_pt == 1 ~ "Democrat",
    pol_7_pt == 2 ~ "Democrat",
    pol_7_pt == 3 ~ "Democrat",
    pol_7_pt == 5 ~ "Republican",
    pol_7_pt == 6 ~ "Republican",
    pol_7_pt == 7 ~ "Republican"),
    dem_rep = as.factor(dem_rep),
    dem_rep = fct_drop(dem_rep)) 


```

# Manipulation check

## Participants' own responses to similarity questions

Their responses reveal expected levels of variance in the population: 27.78% enjoy relaxing vacations (vs. 71.60% adventurous), 17.28% enjoy scary movies, and 70.99% enjoy camping (vs. 27.16% staying in and watching TV shows).

```{r, message=FALSE, warning=FALSE}

ccl %>% 
  group_by(vacation) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
   kable(col.names = c("Vacation Preference",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

ccl %>% 
  group_by(scary_movie) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
   kable(col.names = c("Enjoy Scary Movies?",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

ccl %>% 
  group_by(outdoor_art) %>% 
  summarize(count = n(),
            percent = n()/162*100) %>% 
   kable(col.names = c("Prefer Camping or Staying In and Watching TV Shows?",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

```


## Counts in each experimental condition

79 in the dissimilarity condition, 82 in the similarity condition.
```{r, message=FALSE, warning=FALSE}
ccl %>% 
  group_by(exp_condition) %>% 
  summarize(count = n()) %>% 
  kable(col.names = c("Experimental Condition",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```


# Calculate MLR stereotyping and projection constructs

Used an iterative for loop process.

```{r, message=FALSE, warning=FALSE}

# Use `pivot_longer()` to make the data tidy and have variables for: reason_number, self_rankings, stereotype_rankings, robert_rankings
ccl_long <- ccl %>% 
  pivot_longer(
    cols = s1:r8,
    names_to = c(".value","reason_number"),
    names_pattern = "(.)(.)",
    values_drop_na = TRUE
  )


#Create subset with key variables
key_variables<-ccl_long %>% 
  select(id,reason_number,exp_condition,s,g,r, pol_7_pt, dem_rep, gender_bin,lib_con_num, lib_con) %>% 
  rename(self_rankings = s,
         stereotype_rankings = g,
         robert_rankings = r) %>% 
  add_column(projection = 0) %>% # Adding two new cols. to get ready for regressions on a loop
  add_column(stereotyping = 0)

#Calculate the multiple regressions for every participant 

# For loop will iterate through each row of the dataframe
# The scope of every action within the for loop is limited to that single iteration, so no need to manually filter data and calculate regression for each participant
for (i in 1:nrow(key_variables)) {
  
  # This creates a dataframe of one row, the row that the for loop is currently on
  id<-key_variables %>% 
    filter(id==key_variables[[i, 1]])
  
  # This runs the MLR using the single row created above as the dataframe
  temp_lm <- lm(robert_rankings ~ self_rankings + stereotype_rankings, data = id)
  
  # This converts the linear model object created above into an easy to read and easy to access object. This essentially cleans up the output.
  tidy_temp_lm<-broom::tidy(temp_lm)
  
  # This creates a variable to store the beta coefficient for self ranking predicting robert ranking for this single row
  temp_self_rankings<-tidy_temp_lm[2, 2]
  
  # This creates a variable to store the beta coefficient for stereotype ranking predicting robert ranking for this single row
  temp_stereotype_rankings<-tidy_temp_lm[3,2]
  
  # The last two lines store the variables created above in columns in the original dataframe in the row that the for loop is currently on
  key_variables[i, 12]<-temp_self_rankings
  key_variables[i, 13]<-temp_stereotype_rankings
}

```


## Summary table: M's and SD's key DVs by condition

```{r, message=FALSE, warning=FALSE}

key_variables %>% 
  group_by(exp_condition) %>% 
  summarize(mean_projection = mean(projection),
            sd_projection = sd(projection),
            mean_stereotyping = mean(stereotyping, na.rm = TRUE),
            sd_stereotyping = sd(stereotyping, na.rm = TRUE)) %>% 
    kable(col.names = c("Experimental Condition",
                      "Ames Projection (M)",
                      "Ames Projection (SD)",
                      "Ames Stereotyping (M)",
                      "Ames Stereotyping (SD)")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")


```


# 2 x 2 Mixed ANOVA: Condition on Ames DV

## Create subset of variables for key analysis

```{r, message=FALSE, warning=FALSE}

# Create a subset of only the variables I need for this analysis: id, exp_condition, projection scores, and stereotyping scores
# Gather the columns projection and stereotyping into long format.
# Convert id and exp_condition into factor variables

anova_data <- key_variables %>% 
  select(id, exp_condition, projection, stereotyping) %>% 
  gather(key = "ranking", value = "score", projection, stereotyping) %>% 
  convert_as_factor(id, ranking) %>% 
  unique() %>% 
  mutate(exp_condition = as_factor(exp_condition)) %>% 
  drop_na()

```

## Conduct the ANOVA and contrasts

```{r, message=FALSE, warning=FALSE}

#2-WAY REPEATED MEASURES ANOVA
ames_anova <- lme(score ~ ranking * exp_condition, random=~1|id, data = anova_data) 
anova(ames_anova) 


#Post-Hoc Tests: Multiple Comparisons in Linear Mixed Effect Models

# running emmeans()
# emmeans(ames_anova, pairwise ~ exp_condition*ranking)


# running pairs()
#emm1 <- emmeans(ames_anova, ~ exp_condition*ranking)
#pairs(emm1, simple = "exp_condition")

```

## Report results

The hypothesis was not supported: participants in the similarity condition neither showed significantly greater projection (M = 0.0937, SD = .45) than those in the dissimilarity condition (M = 0.0788, SD = .43), t(158) = .21, p = .99, **SE = .049, 95% CI = [.097, .10],  nor significantly less stereotyping (M = 0.4990, SD = 0.47)  than those in the dissimilarity condition (M = 0.5638, SD = 0.43), t(158) = -.92, p = .80, SE = .050, 95% CI = [.096, .104]. This result was confirmed by the two-way mixed ANOVA: no significant interaction was found between experimental condition and the within-subjects factor on projection and stereotyping scores, F(1,158) = .68, p = .41.


## Calculate the SE and 95% CI for within-subjects

Used [this resource](http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/) on plotting means and error bars in ggplot2. **NOTE**: It uses `Rmisc::summarySE()` which creates some conflicts with `here` and `dplyr`. Might need to install and uninstall `Rmisc` and `plyr` after I obtain these stats and make the graphs, comment out code that wont run, or use package::function notation.

[Another resource](https://johanneskarl.netlify.app/post/errors/withing-and-between-subjects-errors/) on plotting within subjects errors.


### First, install 3 helper functions:

#### 1) SummarySE

```{r, message=FALSE, warning=FALSE}
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}
```

#### 2) NormDataWithin

```{r, message=FALSE, warning=FALSE}

## Norms the data within specified groups in a data frame; it normalizes each
## subject (identified by idvar) so that they have the same mean, within each group
## specified by betweenvars.
##   data: a data frame.
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   na.rm: a boolean that indicates whether to ignore NA's
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
    library(plyr)

    # Measure var on left, idvar + between vars on right of formula.
    data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
     .fun = function(xx, col, na.rm) {
        c(subjMean = mean(xx[,col], na.rm=na.rm))
      },
      measurevar,
      na.rm
    )

    # Put the subject means with original data
    data <- merge(data, data.subjMean)

    # Get the normalized data in a new column
    measureNormedVar <- paste(measurevar, "_norm", sep="")
    data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                               mean(data[,measurevar], na.rm=na.rm)

    # Remove this subject mean column
    data$subjMean <- NULL

    return(data)
}



```

#### 3) SummarySEwithin


```{r, warning=FALSE, message=FALSE}


# The function (Rmisc::summarySEwithin) computes the errors accounting for the non-independent nature of the observations.

## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summarized
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {

  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
    FUN=is.factor, FUN.VALUE=logical(1))

  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }

  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL

  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)

  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")

  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                           FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )

  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor

  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}


within <- Rmisc::summarySEwithin(data = anova_data, measurevar = "score",
                                 betweenvars = "exp_condition",
                                 withinvars = "ranking",
                                 idvar = "id")

within

between <- Rmisc::summarySE(anova_data, measurevar="score", groupvars=c("ranking","exp_condition"))
between

```


## Visualize the 2x2 Mixed ANOVA

### First, make sure the data is in long format (already is)
### Then, summarize the data with `summarySEwithin()` and make the graph

Note that I get different output if I use the `within` and `between` functions. The first is within, the second is between. The within-subjects errors are considerably smaller as a result of accounting for the non-independence. 

Adjusts the error bars so that inter-subject variability is removed as in Loftus and Masson (1994).
```{r, warning=FALSE, message=FALSE}

## Summarize the data using `summarySE()`
within <- Rmisc::summarySEwithin(data = anova_data, measurevar = "score",
                                 betweenvars = "exp_condition",
                                 withinvars = "ranking",
                                 idvar = "id")

within

##Note that I get different results if I do it with the between function:
between <- Rmisc::summarySE(anova_data, measurevar="score", groupvars=c("ranking","exp_condition"))
between

#The first function (Rmisc::summarySE) computes errors without considering that #the observations are not independent. The second function #(Rmisc::summarySEwithin) computes the errors accounting for the non-independent #nature of the observations

## This is plotting the 'within' summarized data. The means are different from what I've found when doing group_by::summarize. It looks like summarySEwithin() reports the means AFTER controlling for variability within individuals.
## Error bars represent standard error of the mean
ggplot(within, aes(x=ranking, y=score, fill=exp_condition)) + 
    geom_bar(position=position_dodge(), stat="identity",
             colour="black", # Use black outlines,
             size=.3) + # Thinner lines
    geom_errorbar(aes(ymin=score-se, ymax=score+se),
                  size=.3,    # Thinner lines
                  width=.2,
                  position=position_dodge(.9)) +
    xlab("") +
    ylab("Mean standardized beta") +
    scale_fill_hue(name="Experimental condition", # Legend label, use darker colors
                   breaks=c("Similar", "Different"),
                   labels=c("Similarity", "Dissimilarity")) +
    ggtitle("Projection and Stereotyping as a\nfunction of Experimental Condition") +
    scale_y_continuous() +
     scale_x_discrete(breaks=c("projection","stereotyping"),
        labels=c("Projection", "Stereotyping"))+
    theme_classic() +
    scale_y_continuous(expand = c(0,0),
                       breaks = seq(0,0.9,0.1))


# Save the ggplot
ggsave(here::here("figures", "ames_anova_viz_all_within.png"), width = 5, height = 5)


## Plot the between group means with within-subj errors:
##Error bars represent standard error of the mean
ggplot(between, aes(x=ranking, y=score, fill=exp_condition)) + 
    geom_bar(position=position_dodge(), stat="identity",
             colour="black", # Use black outlines,
             size=.3) + # Thinner lines
    geom_errorbar(aes(ymin=score-se, ymax=score+se),
                  size=.3,    # Thinner lines
                  width=.2,
                  position=position_dodge(.9), data = within) +
    xlab("") +
    ylab("Mean standardized beta") +
    scale_fill_hue(name="Experimental condition", # Legend label, use darker colors
                   breaks=c("Similar", "Different"),
                   labels=c("Similarity", "Dissimilarity")) +
    ggtitle("Projection and Stereotyping as a\nfunction of Experimental Condition") +
    scale_y_continuous() +
     scale_x_discrete(breaks=c("projection","stereotyping"),
        labels=c("Projection", "Stereotyping"))+
    theme_classic() +
    scale_y_continuous(expand = c(0,0),
                       breaks = seq(0,0.9,0.1))

# Save the ggplot
ggsave(here::here("figures", "ames_anova_viz_between_withinerrorbars.png"), width = 5, height = 5)

```
*Note*. Error bars show standard errors.


# Moderation analysis: Lib/Con on Ames Stereotyping/Projection (2-Way between-subjects ANOVA)

AMES PROJECTION:
The interaction between experimental condition and lib/con on the Ames measure of projection approached significance, *F*(1,152) = 2.85, *p* = .0934. Paired contrasts showed that in the dissimilarity condition, there was a significant difference in conservatives' and liberals' level of projection such that conservatives projected more by 0.2158 than liberals, on average, (Ms: .2018 vs. -0.0140, respectively) *t*(152) = 2.084, *p* = 0.0388. All other paired contrasts were not significant. 


AMES STEREOTYPING:
The interaction between experimental condition and lib/con on the Ames measure of stereotyping approached significance, *F*(1,151) = 3.358, *p* = .0689. Paired contrasts showed that, for liberals, the effect of experimental condition on stereotyping approached significance such that liberals in the dissimilarity condition stereotyped 0.147 units more on average than those liberals in the similarity condition (Ms: 0.615 vs. 0.468), *t*(151) = 1.658, *p* = 0.0993. All other paired contrasts were not significant.


```{r, warning=FALSE, message=FALSE, results='hide'}

## Create a subset of variables I need
libcon_subset <- key_variables %>% 
  select(id, lib_con, lib_con_num, pol_7_pt, dem_rep, exp_condition, projection, stereotyping) %>% 
  unique()

# Ames Projection and Stereotyping:

#Two-way anova: lib_con (lib vs. con) and Condition (Sim/Diff) on projection:
libcon1 <- aov(projection ~ lib_con + exp_condition + lib_con:exp_condition, data = libcon_subset)
summary(libcon1)


#Two-way anova: lib_con (lib vs. con)  and Condition (Sim/Diff) on stereotyping:
libcon2 <- aov(stereotyping ~ lib_con  + exp_condition + lib_con:exp_condition, data = libcon_subset)
summary(libcon2)

# CONTRASTS
contrasts1 <- emmeans(libcon1, pairwise ~ exp_condition*lib_con)
contrasts1

contrasts1_pairs <- emmeans(libcon1, ~ exp_condition*lib_con)
pairs(contrasts1_pairs, simple = "each")

contrasts2 <- emmeans(libcon2, pairwise ~ exp_condition*lib_con)
contrasts2

contrasts2_pairs <- emmeans(libcon2, ~ exp_condition*lib_con)
pairs(contrasts2_pairs, simple = "each")

```

## Visualize the Ideology*Condition Interaction on PROJECTION

Plot with error bars. I can do regular between (not within) `summarySE()` since I am plotting a between-subjects two-way ANOVA.
```{r, message=FALSE, warning=FALSE}
libcon_subset <- libcon_subset %>% 
  drop_na()

# First, summarize the data using `summarySE()`:
lib_con_projection<- Rmisc::summarySE(libcon_subset, measurevar="projection", groupvars=c("lib_con","exp_condition"))
lib_con_projection

##Error bars represent standard error of the mean
ggplot(lib_con_projection, aes(x=lib_con, y=projection, fill=exp_condition)) + 
    geom_bar(position=position_dodge(), stat="identity",
             colour="black", # Use black outlines,
             size=.3) + # Thinner lines
    geom_errorbar(aes(ymin=projection-se, ymax=projection+se),
                  size=.3,    # Thinner lines
                  width=.2,
                  position=position_dodge(.9)) +
    xlab("") +
    ylab("Mean standardized beta") +
    scale_fill_hue(name="Experimental condition", # Legend label, use darker colors
                   breaks=c("Similar", "Different"),
                   labels=c("Similarity", "Dissimilarity")) +
    ggtitle("Projection as function of\nExperimental Condition and Political Ideology") +
    scale_y_continuous() +
    theme_classic() 

# Save the ggplot
ggsave(here::here("figures", "libcon_projection.png"), width = 5, height = 5)

```
*Note*. Error bars show standard errors. 101 Liberals and 40 Moderates/Conservatives were included in the analysis.


## Visualize the Ideology*Condition Interaction on STEREOTYPING


```{r, message=FALSE, warning=FALSE}

# First, summarize the data using `summarySE()`:
lib_con_stereotyping<- Rmisc::summarySE(libcon_subset, measurevar="stereotyping", groupvars=c("lib_con","exp_condition"))
lib_con_stereotyping

##Error bars represent standard error of the mean
ggplot(lib_con_stereotyping, aes(x=lib_con, y=stereotyping, fill=exp_condition)) + 
    geom_bar(position=position_dodge(), stat="identity",
             colour="black", # Use black outlines,
             size=.3) + # Thinner lines
    geom_errorbar(aes(ymin=stereotyping-se, ymax=stereotyping+se),
                  size=.3,    # Thinner lines
                  width=.2,
                  position=position_dodge(.9)) +
    xlab("") +
    ylab("Mean standardized beta") +
    scale_fill_hue(name="Experimental condition", # Legend label, use darker colors
                   breaks=c("Similar", "Different"),
                   labels=c("Similarity", "Dissimilarity")) +
    ggtitle("Stereotyping as function of\nExperimental Condition and Political Ideology") +
    scale_y_continuous(expand = c(0,0),
                       breaks = seq(0,0.8,0.1)) +
    theme_classic() 

# Save the ggplot
ggsave(here::here("figures", "libcon_stereotyping.png"), width = 5, height = 5)

```
*Note*. Error bars show standard errors. 101 Liberals and 40 Moderates/Conservatives were included in the analysis.



# Descriptives

## Age

Participants ranged from 18 to 84 years old (median = 66, *SD* = 16.84 years). Three participants wrote in their own responses: "Older than you," "70 (Retired)," "over 60."

```{r, warning=FALSE,message=FALSE}

# First I created a subset of just the age variable so I could filter out the text responses and convert this variable to numeric. After examining the variable, I saw the 3 text responses so I'm going to filter those out here:

age_subset <- ccl %>% 
  select(age) %>% 
  filter(age != "70 (Retired)") %>% 
  filter(age != "Older than you") %>% 
  filter(age != "over 60") 

#Convert the age variable to numeric
age_subset <- age_subset %>% 
  mutate(age = as.numeric(age)) %>% 
  drop_na()

# Find descriptives
#mean(age_subset$age) # 60.45
#sd(age_subset$age) # 16.84
#min(age_subset$age) # 18
#max(age_subset$age) # 84
#median(age_subset$age) # 66
```


## Gender

```{r, message=FALSE, warning=FALSE}
ccl%>% 
  group_by(gender) %>% 
  summarise(count = n(),
            percent = n()/(161)*100) %>% 
  kable(col.names = c("Gender",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```


## Race/Ethnicity

```{r, message=FALSE, warning=FALSE}
ccl %>% 
  group_by(race) %>% 
  summarize(count = n(),
            percent = n()/161*100) %>% 
  kable(col.names = c("Race/Ethnicity",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left") 

```

```{r, message=FALSE, warning=FALSE}
# Multi-racial (open-ended)
ccl %>% 
  group_by(race_6_text) %>% 
  summarise(count = n()) %>% 
  kable(col.names = c("Race/Ethnicity: Multi-racial - Text",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

# Other (open-ended)
ccl %>% 
  group_by(race_7_text) %>% 
  summarise(count = n()) %>% 
  kable(col.names = c("Race/Ethnicity: Other - Text",
                      "Counts")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

```


## Household income

Median household income category was 5: $50,001 to $75,000.
```{r, message=FALSE, warning=FALSE}

#First, change family income into a factor variable

ccl <- ccl %>% 
  mutate(fam_inc_num = case_when(
    fam_inc == "Under $15,000" ~ 1,
    fam_inc == "$15,001 - $25,000" ~ 2,
    fam_inc == "$25,001 - $35,000" ~ 3,
    fam_inc == "$35,001 - $50,000" ~ 4, 
    fam_inc == "$50,001 - $75,000" ~ 5,
    fam_inc == "$75,001 - $100,000" ~ 6, 
    fam_inc == "$100,001 - $150,000" ~ 7,
    fam_inc == "$Over 150,000" ~ 8))

#median(ccl$fam_inc_num, na.rm = TRUE) # 5
#min(ccl$fam_inc_num, na.rm = TRUE) # 1
#max(ccl$fam_inc_num, na.rm = TRUE) # 7

# Table
ccl %>% 
  group_by(fam_inc) %>% 
  summarise(count = n(),
            percent = n()/161*100) %>% 
  kable(col.names = c("Household Income",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

```


## Political ideology

*M* on 5-point scale (1-Very liberal to 5-Very conservative): 2.17, *SD* = 0.80.
```{r, message=FALSE, warning=FALSE}

ccl %>% 
  group_by(ideology) %>% 
  summarise(count = n(),
            percent = n()/161*100) %>% 
  kable(col.names = c("Political Ideology",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

#mean(ccl$lib_con_num, na.rm = TRUE) #2.17
#sd(ccl$lib_con_num, na.rm = TRUE) #0.80

```


## Political party

*M* on 7-point scale (1-Strong Democrat to 7-Strong Republican): 2.16, *SD* = 1.29.
```{r, message=FALSE, warning=FALSE}

ccl %>% 
  group_by(pol_7_pt_char) %>% 
  summarise(count = n(),
            percent = n()/161*100) %>% 
  kable(col.names = c("Political Party Identification",
                      "Counts",
                      "Percent")) %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")

#mean(ccl$pol_7_pt) #2.16
#sd(ccl$pol_7_pt) #1.29
```




